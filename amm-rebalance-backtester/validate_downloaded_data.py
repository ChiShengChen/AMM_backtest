#!/usr/bin/env python3
"""
é©—è­‰ä¸‹è¼‰çš„5å¹´æ—¥ç·šæ•¸æ“šè³ªé‡
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

def validate_data_file(filepath):
    """é©—è­‰å–®å€‹æ•¸æ“šæ–‡ä»¶"""
    print(f"\n{'='*60}")
    print(f"é©—è­‰æ–‡ä»¶: {os.path.basename(filepath)}")
    print(f"{'='*60}")
    
    try:
        # è®€å–æ•¸æ“š
        df = pd.read_csv(filepath)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"  è¨˜éŒ„æ•¸é‡: {len(df):,}")
        print(f"  æ–‡ä»¶å¤§å°: {os.path.getsize(filepath) / 1024:.1f} KB")
        
        # æ™‚é–“ç¯„åœæª¢æŸ¥
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        time_range = (df['timestamp'].min(), df['timestamp'].max())
        time_span = time_range[1] - time_range[0]
        
        print(f"\nâ° æ™‚é–“ç¯„åœ:")
        print(f"  é–‹å§‹æ™‚é–“: {time_range[0]}")
        print(f"  çµæŸæ™‚é–“: {time_range[1]}")
        print(f"  ç¸½è·¨åº¦: {time_span.days} å¤©")
        
        # æ•¸æ“šå®Œæ•´æ€§æª¢æŸ¥
        print(f"\nğŸ” æ•¸æ“šå®Œæ•´æ€§:")
        missing_values = df.isnull().sum().sum()
        duplicate_timestamps = df['timestamp'].duplicated().sum()
        print(f"  ç¼ºå¤±å€¼: {missing_values}")
        print(f"  é‡è¤‡æ™‚é–“æˆ³: {duplicate_timestamps}")
        
        # åƒ¹æ ¼æ•¸æ“šæª¢æŸ¥
        print(f"\nğŸ’° åƒ¹æ ¼æ•¸æ“š:")
        price_range = (df['low'].min(), df['high'].max())
        print(f"  æœ€ä½åƒ¹: ${price_range[0]:.2f}")
        print(f"  æœ€é«˜åƒ¹: ${price_range[1]:.2f}")
        print(f"  åƒ¹æ ¼ç¯„åœ: ${price_range[1] - price_range[0]:.2f}")
        
        # äº¤æ˜“é‡æª¢æŸ¥
        print(f"\nğŸ“ˆ äº¤æ˜“é‡æ•¸æ“š:")
        total_volume = df['volume'].sum()
        avg_volume = df['volume'].mean()
        print(f"  ç¸½äº¤æ˜“é‡: {total_volume:,.2f}")
        print(f"  å¹³å‡äº¤æ˜“é‡: {avg_volume:,.2f}")
        
        # æ•¸æ“šä¸€è‡´æ€§æª¢æŸ¥
        print(f"\nâœ… æ•¸æ“šä¸€è‡´æ€§:")
        price_consistency = all(df['low'] <= df['high']) and all(df['low'] <= df['close']) and all(df['close'] <= df['high'])
        volume_consistency = all(df['volume'] >= 0)
        print(f"  åƒ¹æ ¼ä¸€è‡´æ€§: {'âœ…' if price_consistency else 'âŒ'}")
        print(f"  äº¤æ˜“é‡ä¸€è‡´æ€§: {'âœ…' if volume_consistency else 'âŒ'}")
        
        # æ™‚é–“é–“éš”æª¢æŸ¥
        time_gaps = df['timestamp'].diff().dropna()
        expected_gap = pd.Timedelta(days=1)
        gap_consistency = (time_gaps == expected_gap).mean()
        print(f"  æ™‚é–“é–“éš”ä¸€è‡´æ€§: {gap_consistency:.1%}")
        
        # è¨ˆç®—å¹´åŒ–æ”¶ç›Šç‡
        if len(df) > 1:
            start_price = df.iloc[0]['close']
            end_price = df.iloc[-1]['close']
            years = time_span.days / 365.25
            annual_return = ((end_price / start_price) ** (1/years) - 1) * 100
            print(f"\nğŸ“Š å¹´åŒ–æ”¶ç›Šç‡: {annual_return:.2f}%")
        
        # æ•¸æ“šè³ªé‡è©•åˆ†
        quality_score = 0
        if missing_values == 0: quality_score += 20
        if duplicate_timestamps == 0: quality_score += 20
        if price_consistency: quality_score += 20
        if volume_consistency: quality_score += 20
        if gap_consistency > 0.95: quality_score += 20
        
        print(f"\nğŸ† æ•¸æ“šè³ªé‡è©•åˆ†: {quality_score}/100")
        
        if quality_score >= 80:
            print("  ğŸ‰ æ•¸æ“šè³ªé‡å„ªç§€ï¼")
        elif quality_score >= 60:
            print("  âœ… æ•¸æ“šè³ªé‡è‰¯å¥½")
        else:
            print("  âš ï¸ æ•¸æ“šè³ªé‡éœ€è¦æ”¹é€²")
        
        return {
            'filepath': filepath,
            'quality_score': quality_score,
            'record_count': len(df),
            'time_span_days': time_span.days,
            'missing_values': missing_values,
            'duplicate_timestamps': duplicate_timestamps
        }
        
    except Exception as e:
        print(f"âŒ é©—è­‰å¤±æ•—: {e}")
        return None

def create_summary_report(validation_results):
    """å‰µå»ºç¸½çµå ±å‘Š"""
    print(f"\n{'='*80}")
    print("ğŸ“‹ æ•¸æ“šé©—è­‰ç¸½çµå ±å‘Š")
    print(f"{'='*80}")
    
    if not validation_results:
        print("âŒ æ²’æœ‰æœ‰æ•ˆçš„é©—è­‰çµæœ")
        return
    
    # çµ±è¨ˆä¿¡æ¯
    total_files = len(validation_results)
    successful_validations = len([r for r in validation_results if r is not None])
    avg_quality_score = np.mean([r['quality_score'] for r in validation_results if r is not None])
    total_records = sum([r['record_count'] for r in validation_results if r is not None])
    total_days = sum([r['time_span_days'] for r in validation_results if r is not None])
    
    print(f"ğŸ“Š ç¸½é«”çµ±è¨ˆ:")
    print(f"  ç¸½æ–‡ä»¶æ•¸: {total_files}")
    print(f"  æˆåŠŸé©—è­‰: {successful_validations}")
    print(f"  å¹³å‡è³ªé‡è©•åˆ†: {avg_quality_score:.1f}/100")
    print(f"  ç¸½è¨˜éŒ„æ•¸: {total_records:,}")
    print(f"  ç¸½æ™‚é–“è·¨åº¦: {total_days:,} å¤©")
    
    # å„æ–‡ä»¶è©³ç´°ä¿¡æ¯
    print(f"\nğŸ“ æ–‡ä»¶è©³ç´°ä¿¡æ¯:")
    for result in validation_results:
        if result:
            filename = os.path.basename(result['filepath'])
            print(f"  {filename}:")
            print(f"    è³ªé‡è©•åˆ†: {result['quality_score']}/100")
            print(f"    è¨˜éŒ„æ•¸: {result['record_count']:,}")
            print(f"    æ™‚é–“è·¨åº¦: {result['time_span_days']} å¤©")
    
    # å»ºè­°
    print(f"\nğŸ’¡ å»ºè­°:")
    if avg_quality_score >= 80:
        print("  ğŸ‰ æ‰€æœ‰æ•¸æ“šè³ªé‡å„ªç§€ï¼Œå¯ä»¥ç›´æ¥ç”¨æ–¼å›æ¸¬ï¼")
    elif avg_quality_score >= 60:
        print("  âœ… æ•¸æ“šè³ªé‡è‰¯å¥½ï¼Œå»ºè­°æª¢æŸ¥å€‹åˆ¥å•é¡Œå¾Œä½¿ç”¨")
    else:
        print("  âš ï¸ æ•¸æ“šè³ªé‡éœ€è¦æ”¹é€²ï¼Œå»ºè­°é‡æ–°ä¸‹è¼‰")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” é–‹å§‹é©—è­‰ä¸‹è¼‰çš„5å¹´æ—¥ç·šæ•¸æ“š...")
    
    # æ•¸æ“šç›®éŒ„
    data_dir = "data/5year_daily"
    
    if not os.path.exists(data_dir):
        print(f"âŒ æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {data_dir}")
        return
    
    # ç²å–æ‰€æœ‰ CSV æ–‡ä»¶
    csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
    
    if not csv_files:
        print(f"âŒ åœ¨ {data_dir} ä¸­æ²’æœ‰æ‰¾åˆ° CSV æ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} å€‹æ•¸æ“šæ–‡ä»¶")
    
    # é©—è­‰æ¯å€‹æ–‡ä»¶
    validation_results = []
    for csv_file in sorted(csv_files):
        filepath = os.path.join(data_dir, csv_file)
        result = validate_data_file(filepath)
        validation_results.append(result)
    
    # å‰µå»ºç¸½çµå ±å‘Š
    create_summary_report(validation_results)
    
    print(f"\nğŸ¯ é©—è­‰å®Œæˆï¼æ•¸æ“šå·²æº–å‚™å¥½ç”¨æ–¼ AMM å›æ¸¬")

if __name__ == "__main__":
    main()
